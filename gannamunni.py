import asyncio
import aiohttp
import json
import re
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime, date

@dataclass
class Writer:
    id: int
    doctor_id: Optional[int]
    profile: str
    nickname: str
    level: int
    engagement_type: Optional[str]

@dataclass
class Photo:
    url: str

@dataclass
class Comment:
    id: int
    status: int
    writer: Writer
    create_time: str
    reply_comment_id: Optional[int]
    is_admin: bool
    edited: bool
    contents: str
    has_thumb_up: bool
    thumb_up_count: int
    comment_count: int
    callee_nickname: Optional[str]
    lang: str
    translate_result: Optional[str]
    show_original_content: bool
    replies: List['Comment']

@dataclass
class Article:
    id: int
    category_id: int
    category_name: str
    writer: Writer
    writer_doctor_id: Optional[int]
    has_thumb_up: bool
    comment_count: int
    thumb_up_count: int
    view_count: int
    create_time: str
    edited: bool
    title: str
    contents: str
    photos: List[Photo]
    lang: str
    has_doctor_comment: bool
    translate_result: Optional[str]
    is_admin: bool = False
    has_subscribed: bool = False
    comments: List[Comment] = None

class GangnamUnniAPI:
    def __init__(self):
        self.base_url = "https://www.gangnamunni.com"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Authorization": "a70ba5dec9424aeb99e956a19cba87a3",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "empty",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Site": "same-origin",
            "Cache-Control": "no-cache",
            "Pragma": "no-cache",
        }
    
    async def get_article_list(self, category: str = "hospital_question", page: int = 1, limit: int = 20) -> List[Article]:
        """
        ê°•ë‚¨ì–¸ë‹ˆ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸ê°’: "hospital_question" - ë³‘ì›ì§ˆë¬¸)
            page: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            limit: í•œ í˜ì´ì§€ë‹¹ ê²Œì‹œê¸€ ìˆ˜ (ê¸°ë³¸ê°’: 20)
        
        Returns:
            List[Article]: ê²Œì‹œê¸€ ëª©ë¡
        """
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                # API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
                url = f"{self.base_url}/api/v2/community"
                
                # í˜ì´ì§€ ê³„ì‚° (APIëŠ” start íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                start = (page - 1) * limit
                
                # ì¹´í…Œê³ ë¦¬ ID ë§¤í•‘
                category_ids = {
                    "hospital_question": 11,  # ë³‘ì›ì§ˆë¬¸
                    "surgery_question": 2,    # ì‹œìˆ /ìˆ˜ìˆ ì§ˆë¬¸
                    "free_chat": 1,           # ììœ ìˆ˜ë‹¤
                    "review": 5,              # ë°œí’ˆí›„ê¸°
                    "ask_doctor": 13,         # ì˜ì‚¬ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”
                }
                
                category_id = category_ids.get(category, 11)
                
                params = {
                    "start": start,
                    "length": limit,
                    "sort": "createTime",
                    "categoryIds": category_id,
                    "draw": 0
                }
                
                async with session.get(url, params=params) as response:
                    if response.status != 200:
                        raise Exception(f"HTTP {response.status}: {response.reason}")
                    
                    json_data = await response.json()
                    
                    # FAIL ì‘ë‹µì´ ë‚˜ì™€ë„ dataê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
                    if json_data.get("reason") == "FAIL" and json_data.get("data") is None:
                        return []
                    
                    # data ë°°ì—´ì—ì„œ ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ
                    articles_data = json_data.get("data", [])
                    
                    articles = []
                    for item in articles_data:
                        article = self._parse_article_from_api(item)
                        articles.append(article)
                    
                    return articles
                    
        except Exception as e:
            print(f"ê²Œì‹œê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            # API ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []
    
    async def get_articles_by_date(self, target_date: str, category: str = "hospital_question") -> List[Article]:
        """
        íŠ¹ì • ë‚ ì§œì˜ ê²Œì‹œê¸€ì„ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        
        Args:
            target_date: ìˆ˜ì§‘í•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ì˜ˆ: "2024-01-15")
            category: ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸ê°’: "hospital_question" - ë³‘ì›ì§ˆë¬¸)
        
        Returns:
            List[Article]: í•´ë‹¹ ë‚ ì§œì˜ ê²Œì‹œê¸€ ëª©ë¡
        """
        try:
            # ë‚ ì§œ í˜•ì‹ ê²€ì¦
            target_date_obj = datetime.strptime(target_date, "%Y-%m-%d").date()
        except ValueError:
            print(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 2024-01-15)")
            return []
        
        all_articles = []
        page = 1
        max_pages = 100  # ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì œí•œ
        consecutive_empty_pages = 0  # ì—°ì†ìœ¼ë¡œ ë¹ˆ í˜ì´ì§€ê°€ ë‚˜ì˜¨ íšŸìˆ˜
        max_consecutive_empty = 3  # ìµœëŒ€ ì—°ì† ë¹ˆ í˜ì´ì§€ ìˆ˜
        found_target_date = False  # ëª©í‘œ ë‚ ì§œ ê²Œì‹œê¸€ì„ ì°¾ì•˜ëŠ”ì§€ í™•ì¸
        
        while page <= max_pages and consecutive_empty_pages < max_consecutive_empty:
            try:
                # í˜„ì¬ í˜ì´ì§€ì˜ ê²Œì‹œê¸€ ê°€ì ¸ì˜¤ê¸°
                page_articles = await self.get_article_list(category=category, page=page, limit=20)
                
                if not page_articles:
                    consecutive_empty_pages += 1
                    page += 1
                    await asyncio.sleep(1)
                    continue
                
                # ë‚ ì§œë³„ í•„í„°ë§
                target_date_articles = []
                older_articles_found = False
                
                for article in page_articles:
                    try:
                        article_date = self._parse_article_date(article.create_time)
                        
                        if article_date == target_date_obj:
                            target_date_articles.append(article)
                            found_target_date = True
                        elif article_date < target_date_obj:
                            # ë” ì˜¤ë˜ëœ ê²Œì‹œê¸€ì´ ë‚˜ì˜¤ë©´ ìˆ˜ì§‘ ì¤‘ë‹¨
                            older_articles_found = True
                            break
                        elif article_date > target_date_obj:
                            # ë” ìµœì‹  ê²Œì‹œê¸€ì´ ë‚˜ì˜¤ë©´ ê³„ì† ì§„í–‰
                            continue
                            
                    except (ValueError, IndexError) as e:
                        continue
                
                # í•´ë‹¹ ë‚ ì§œì˜ ê²Œì‹œê¸€ ì¶”ê°€
                if target_date_articles:
                    all_articles.extend(target_date_articles)
                
                # ë” ì˜¤ë˜ëœ ê²Œì‹œê¸€ì´ ë°œê²¬ë˜ë©´ ìˆ˜ì§‘ ì¤‘ë‹¨
                if older_articles_found:
                    break
                
                # í˜ì´ì§€ ê°„ ë”œë ˆì´ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                await asyncio.sleep(1)
                
                page += 1
                
            except Exception as e:
                break
        
        return all_articles
    
    def _parse_article_date(self, time_str: str) -> date:
        """
        ê²Œì‹œê¸€ì˜ ì‹œê°„ ë¬¸ìì—´ì„ ë‚ ì§œë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            time_str: ì‹œê°„ ë¬¸ìì—´ (YYYY-MM-DD HH:MM:SS í˜•ì‹)
        
        Returns:
            date: íŒŒì‹±ëœ ë‚ ì§œ
        """
        try:
            # "YYYY-MM-DD HH:MM:SS" í˜•ì‹ì—ì„œ ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            date_str = time_str.split(' ')[0]
            result = datetime.strptime(date_str, "%Y-%m-%d").date()
            return result
        except (ValueError, IndexError) as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ ë°˜í™˜
            return datetime.now().date()
    

    
    async def get_comments(self, article_id: int) -> List[Comment]:
        """
        íŠ¹ì • ê²Œì‹œê¸€ì˜ ëŒ“ê¸€ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            article_id: ê²Œì‹œê¸€ ID
        
        Returns:
            List[Comment]: ëŒ“ê¸€ ëª©ë¡
        """
        print(f"        ğŸ” ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘: ê²Œì‹œê¸€ ID {article_id}")
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                # ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ URL
                url = f"{self.base_url}/community/{article_id}"
                print(f"        ğŸ“¡ í˜ì´ì§€ URL: {url}")
                
                async with session.get(url) as response:
                    print(f"        ğŸ“Š HTTP ìƒíƒœ: {response.status}")
                    
                    if response.status != 200:
                        error_msg = f"HTTP {response.status}: {response.reason}"
                        print(f"        âŒ HTTP ì˜¤ë¥˜: {error_msg}")
                        raise Exception(error_msg)
                    
                    html_content = await response.text()
                    print(f"        ğŸ“„ HTML í¬ê¸°: {len(html_content)} bytes")
                    
                    # __NEXT_DATA__ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ
                    import re
                    import json
                    
                    # __NEXT_DATA__ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ ì°¾ê¸°
                    next_data_pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
                    match = re.search(next_data_pattern, html_content, re.DOTALL)
                    
                    if not match:
                        print(f"        âŒ __NEXT_DATA__ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return []
                    
                    try:
                        next_data = json.loads(match.group(1))
                        print(f"        âœ… __NEXT_DATA__ íŒŒì‹± ì„±ê³µ")
                        
                        # ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ
                        comments_data = next_data.get("props", {}).get("pageProps", {}).get("communityDocumentComments", [])
                        print(f"        ğŸ“‹ ì›ë³¸ ëŒ“ê¸€ ë°ì´í„°: {len(comments_data)}ê°œ")
                        
                        comments = []
                        for i, comment_data in enumerate(comments_data):
                            try:
                                comment = self._parse_comment_from_ssr(comment_data)
                                comments.append(comment)
                                print(f"        âœ… ëŒ“ê¸€ {i+1} íŒŒì‹± ì„±ê³µ: ID {comment.id}, ì‘ì„±ì {comment.writer.nickname}")
                            except Exception as parse_error:
                                print(f"        âš ï¸  ëŒ“ê¸€ {i+1} íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
                        
                        print(f"        ğŸ‰ ì´ {len(comments)}ê°œ ëŒ“ê¸€ íŒŒì‹± ì™„ë£Œ")
                        return comments
                        
                    except json.JSONDecodeError as e:
                        print(f"        âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        return []
                    
        except Exception as e:
            print(f"        âŒ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            print(f"        ğŸ” ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (pass ì²˜ë¦¬)
            return []
    

    
    def _parse_article_from_api(self, data: Dict) -> Article:
        """
        API ì‘ë‹µì˜ ê²Œì‹œê¸€ ë°ì´í„°ë¥¼ Article ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            data: API ì‘ë‹µì˜ ê²Œì‹œê¸€ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            Article: íŒŒì‹±ëœ ê²Œì‹œê¸€ ê°ì²´
        """
        # ì‘ì„±ì ì •ë³´ íŒŒì‹± (API í˜•ì‹)
        writer = Writer(
            id=data.get("writerId", 0),
            doctor_id=data.get("writerDoctorId"),
            profile=data.get("writerProfile", ""),
            nickname=data.get("writerNickName", ""),
            level=data.get("writerLevel", 1),
            engagement_type=data.get("writerEngagementType")
        )
        
        # ì‚¬ì§„ ì •ë³´ íŒŒì‹± (APIì—ì„œëŠ” ë¬¸ìì—´ ë°°ì—´)
        photos = []
        for photo_url in data.get("photos", []):
            photo = Photo(url=photo_url)
            photos.append(photo)
        
        # createTimeì„ íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜
        create_time_timestamp = data.get("createTime", 0)
        if create_time_timestamp:
            create_time_str = self._timestamp_to_readable_time(create_time_timestamp)
        else:
            create_time_str = ""
        
        # ê²Œì‹œê¸€ ê°ì²´ ìƒì„±
        article = Article(
            id=data.get("id", 0),
            category_id=data.get("categoryId", 0),
            category_name=data.get("categoryName", ""),
            writer=writer,
            writer_doctor_id=data.get("writerDoctorId"),
            has_thumb_up=data.get("hasThumbUp", False),
            comment_count=data.get("commentCount", 0),
            thumb_up_count=data.get("thumbUpCount", 0),
            view_count=data.get("viewCount", 0),
            create_time=create_time_str,
            edited=data.get("edited", False),
            title="",  # APIì—ëŠ” title í•„ë“œê°€ ì—†ìŒ
            contents=data.get("contents", ""),
            photos=photos,
            lang=data.get("lang", "ko"),
            has_doctor_comment=data.get("hasDoctorComment", False),
            translate_result=data.get("translateResult")
        )
        
        return article
    
    def _timestamp_to_readable_time(self, timestamp: int) -> str:
        """
        íƒ€ì„ìŠ¤íƒ¬í”„(ë°€ë¦¬ì´ˆ)ë¥¼ ì •í™•í•œ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            timestamp: ë°€ë¦¬ì´ˆ íƒ€ì„ìŠ¤íƒ¬í”„
        
        Returns:
            str: ì •í™•í•œ ì‹œê°„ í˜•ì‹ (YYYY-MM-DD HH:MM:SS)
        """
        from datetime import datetime
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
        dt = datetime.fromtimestamp(timestamp / 1000)
        
        # ì •í™•í•œ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    
    def _parse_article(self, data: Dict) -> Article:
        """
        ê²Œì‹œê¸€ ë°ì´í„°ë¥¼ Article ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            data: ê²Œì‹œê¸€ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            Article: íŒŒì‹±ëœ ê²Œì‹œê¸€ ê°ì²´
        """
        # ì‘ì„±ì ì •ë³´ íŒŒì‹±
        writer_data = data.get("writer", {})
        writer = Writer(
            id=writer_data.get("id", 0),
            doctor_id=writer_data.get("doctorId"),
            profile=writer_data.get("profile", ""),
            nickname=writer_data.get("nickname", ""),
            level=writer_data.get("level", 1),
            engagement_type=writer_data.get("engagementType")
        )
        
        # ì‚¬ì§„ ì •ë³´ íŒŒì‹±
        photos = []
        for photo_data in data.get("photos", []):
            photo = Photo(url=photo_data.get("url", ""))
            photos.append(photo)
        
        # ê²Œì‹œê¸€ ê°ì²´ ìƒì„±
        article = Article(
            id=data.get("id", 0),
            category_id=data.get("categoryId", 0),
            category_name=data.get("categoryName", ""),
            writer=writer,
            writer_doctor_id=data.get("writerDoctorId"),
            has_thumb_up=data.get("hasThumbUp", False),
            comment_count=data.get("commentCount", 0),
            thumb_up_count=data.get("thumbUpCount", 0),
            view_count=data.get("viewCount", 0),
            create_time=data.get("createTime", ""),
            edited=data.get("edited", False),
            title=data.get("title", ""),
            contents=data.get("contents", ""),
            photos=photos,
            lang=data.get("lang", "ko"),
            has_doctor_comment=data.get("hasDoctorComment", False),
            translate_result=data.get("translateResult")
        )
        
        return article
    

    
    def _parse_comment_from_ssr(self, data: Dict) -> Comment:
        """
        SSR ë°ì´í„°ì˜ ëŒ“ê¸€ ë°ì´í„°ë¥¼ Comment ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            data: SSR ëŒ“ê¸€ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            Comment: íŒŒì‹±ëœ ëŒ“ê¸€ ê°ì²´
        """
        try:
            # ëŒ“ê¸€ ì‘ì„±ì ì •ë³´ íŒŒì‹± (SSR í˜•ì‹)
            writer_data = data.get("writer", {})
            writer = Writer(
                id=writer_data.get("id", 0),
                doctor_id=writer_data.get("doctorId"),
                profile=writer_data.get("profile", ""),
                nickname=writer_data.get("nickname", ""),
                level=writer_data.get("level", 1),
                engagement_type=writer_data.get("engagementType")
            )
            
            # createTimeì€ ì´ë¯¸ ë¬¸ìì—´ í˜•íƒœ
            create_time_str = data.get("createTime", "")
            
            # ëŒ€ëŒ“ê¸€ íŒŒì‹±
            replies = []
            replies_data = data.get("replies", [])
            if replies_data:
                print(f"          ğŸ”„ ëŒ€ëŒ“ê¸€ {len(replies_data)}ê°œ íŒŒì‹± ì¤‘...")
                for reply_data in replies_data:
                    reply = self._parse_comment_from_ssr(reply_data)
                    replies.append(reply)
            
            # ëŒ“ê¸€ ê°ì²´ ìƒì„±
            comment = Comment(
                id=data.get("id", 0),
                status=data.get("status", 1),
                writer=writer,
                create_time=create_time_str,
                reply_comment_id=data.get("replyCommentId"),
                is_admin=data.get("isAdmin", False),
                edited=data.get("edited", False),
                contents=data.get("contents", ""),
                has_thumb_up=data.get("hasThumbUp", False),
                thumb_up_count=data.get("thumbUpCount", 0),
                comment_count=data.get("commentCount", 0),
                callee_nickname=data.get("calleeNickName"),
                lang=data.get("lang", "ko"),
                translate_result=data.get("translateResult"),
                show_original_content=data.get("showOriginalContent", True),
                replies=replies
            )
            
            return comment
            
        except Exception as e:
            print(f"          âŒ ëŒ“ê¸€ íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"          ğŸ“‹ ì›ë³¸ ë°ì´í„°: {data}")
            raise e
    
    def _parse_comment_from_api(self, data: Dict) -> Comment:
        """
        API ì‘ë‹µì˜ ëŒ“ê¸€ ë°ì´í„°ë¥¼ Comment ê°ì²´ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            data: API ì‘ë‹µì˜ ëŒ“ê¸€ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            Comment: íŒŒì‹±ëœ ëŒ“ê¸€ ê°ì²´
        """
        try:
            # ëŒ“ê¸€ ì‘ì„±ì ì •ë³´ íŒŒì‹± (API í˜•ì‹)
            writer = Writer(
                id=data.get("writerId", 0),
                doctor_id=data.get("writerDoctorId"),
                profile=data.get("writerProfile", ""),
                nickname=data.get("writerNickName", ""),
                level=data.get("writerLevel", 1),
                engagement_type=data.get("writerEngagementType")
            )
            
            # createTimeì„ íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜
            create_time_timestamp = data.get("createTime", 0)
            if create_time_timestamp:
                create_time_str = self._timestamp_to_readable_time(create_time_timestamp)
            else:
                create_time_str = ""
            
            # ëŒ€ëŒ“ê¸€ íŒŒì‹±
            replies = []
            replies_data = data.get("replies", [])
            if replies_data:
                print(f"          ğŸ”„ ëŒ€ëŒ“ê¸€ {len(replies_data)}ê°œ íŒŒì‹± ì¤‘...")
                for reply_data in replies_data:
                    reply = self._parse_comment_from_api(reply_data)
                    replies.append(reply)
            
            # ëŒ“ê¸€ ê°ì²´ ìƒì„±
            comment = Comment(
                id=data.get("id", 0),
                status=data.get("status", 1),
                writer=writer,
                create_time=create_time_str,
                reply_comment_id=data.get("replyCommentId"),
                is_admin=data.get("isAdmin", False),
                edited=data.get("edited", False),
                contents=data.get("contents", ""),
                has_thumb_up=data.get("hasThumbUp", False),
                thumb_up_count=data.get("thumbUpCount", 0),
                comment_count=data.get("commentCount", 0),
                callee_nickname=data.get("calleeNickName"),
                lang=data.get("lang", "ko"),
                translate_result=data.get("translateResult"),
                show_original_content=data.get("showOriginalContent", True),
                replies=replies
            )
            
            return comment
            
        except Exception as e:
            print(f"          âŒ ëŒ“ê¸€ íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"          ğŸ“‹ ì›ë³¸ ë°ì´í„°: {data}")
            raise e
    

    
    async def search_articles(self, keyword: str, category: str = "hospital_question") -> List[Article]:
        """
        í‚¤ì›Œë“œë¡œ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            category: ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸ê°’: "hospital_question")
        
        Returns:
            List[Article]: ê²€ìƒ‰ ê²°ê³¼ ê²Œì‹œê¸€ ëª©ë¡
        """
        try:
            # ì „ì²´ ê²Œì‹œê¸€ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ í‚¤ì›Œë“œ í•„í„°ë§
            articles = await self.get_article_list(category=category, page=1, limit=100)
            
            filtered_articles = []
            for article in articles:
                if (keyword.lower() in article.title.lower() or 
                    keyword.lower() in article.contents.lower() or
                    keyword.lower() in article.writer.nickname.lower()):
                    filtered_articles.append(article)
            
            return filtered_articles
            
        except Exception as e:
            print(f"ê²Œì‹œê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    api = GangnamUnniAPI()
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ê²Œì‹œê¸€ ìˆ˜ì§‘
    target_date = "2025-08-03"
    categories = {
        "hospital_question": "ë³‘ì›ì§ˆë¬¸",
        "surgery_question": "ì‹œìˆ /ìˆ˜ìˆ ì§ˆë¬¸", 
        "free_chat": "ììœ ìˆ˜ë‹¤",
        "review": "ë°œí’ˆí›„ê¸°",
        "ask_doctor": "ì˜ì‚¬ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”"
    }
    
    all_articles = []
    
    for category_key, category_name in categories.items():
        print(f"\n=== {category_name} ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘ ===")
        articles = await api.get_articles_by_date(target_date, category=category_key)
        print(f"{category_name}: {len(articles)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ë¨")
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€
        for article in articles:
            article.category_name = category_name
        
        all_articles.extend(articles)
    
    print(f"\n=== {target_date} ì „ì²´ ê²Œì‹œê¸€ ëª©ë¡ (ì´ {len(all_articles)}ê°œ) ===")
    for i, article in enumerate(all_articles, 1):
        print(f"\n{i}. ê²Œì‹œê¸€ ID: {article.id}")
        print(f"   ì¹´í…Œê³ ë¦¬: {article.category_name}")
        print(f"   ë‚´ìš©: {article.contents}")
        print(f"   ì‘ì„±ì: {article.writer.nickname} (ë ˆë²¨ {article.writer.level})")
        print(f"   ì¡°íšŒìˆ˜: {article.view_count}, ëŒ“ê¸€: {article.comment_count}")
        print(f"   ì‘ì„±ì‹œê°„: {article.create_time}")
        print(f"   ì‚¬ì§„ ìˆ˜: {len(article.photos)}")
        
        # ëŒ“ê¸€ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        if article.comment_count > 0:
            try:
                comments = await api.get_comments(article.id)
                if comments:
                    print(f"   === ëŒ“ê¸€ ëª©ë¡ (ì´ {len(comments)}ê°œ) ===")
                    for j, comment in enumerate(comments, 1):
                        print(f"     {j}. ëŒ“ê¸€ ID: {comment.id}")
                        print(f"        ì‘ì„±ì: {comment.writer.nickname} (ë ˆë²¨ {comment.writer.level})")
                        print(f"        ë‚´ìš©: {comment.contents}")
                        print(f"        ì‘ì„±ì‹œê°„: {comment.create_time}")
                        print(f"        ì¢‹ì•„ìš”: {comment.thumb_up_count}")
                        
                        if comment.replies:
                            print(f"        ëŒ€ëŒ“ê¸€ ìˆ˜: {len(comment.replies)}")
                else:
                    print("   ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"   ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        else:
            print("   ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())

