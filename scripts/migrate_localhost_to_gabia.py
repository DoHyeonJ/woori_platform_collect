#!/usr/bin/env python3
"""
localhostì—ì„œ db.hellobdd2.gabia.ioë¡œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
1. ì½”ë“œì—ì„œ ì†ŒìŠ¤ DB ì„¤ì • (localhost) í•˜ë“œì½”ë”©
2. ì½”ë“œì—ì„œ ëŒ€ìƒ DB ì„¤ì • (db.hellobdd2.gabia.io) í•˜ë“œì½”ë”©
3. ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
4. articles, comments, reviews í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import sys
import os
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, List, Optional
import pymysql
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.logger import get_logger

logger = get_logger("MIGRATION")

class DatabaseMigrator:
    """ë°ì´í„°ë² ì´ìŠ¤ ê°„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì†ŒìŠ¤ DB ì„¤ì • (localhost)
        self.source_config = {
            'host': 'localhost',
            'port': 3306,
            'user': 'root',
            'password': '1234',  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½
            'database': 'woori_collect',
            'charset': 'utf8mb4'
        }
        
        # ëŒ€ìƒ DB ì„¤ì • (db.hellobdd2.gabia.io)
        self.target_config = {
            'host': 'db.hellobdd2.gabia.io',
            'port': 3306,
            'user': 'hellobdd2',
            'password': 'ahdtlfcjstk0805!',  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½
            'database': 'dbhellobdd2',
            'charset': 'utf8mb4'
        }
        
        # SQLAlchemy ì—”ì§„ ìƒì„±
        self.source_engine = self._create_engine(self.source_config)
        self.target_engine = self._create_engine(self.target_config)
        
        # ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„±
        self.SourceSession = sessionmaker(bind=self.source_engine)
        self.TargetSession = sessionmaker(bind=self.target_engine)
    
    def _create_engine(self, config: Dict) -> create_engine:
        """SQLAlchemy ì—”ì§„ ìƒì„±"""
        connection_string = (
            f"mysql+pymysql://{config['user']}:{config['password']}"
            f"@{config['host']}:{config['port']}/{config['database']}"
            f"?charset={config['charset']}"
        )
        
        return create_engine(
            connection_string,
            echo=False,
            pool_pre_ping=True,
            pool_recycle=3600
        )
    
    def check_connections(self) -> bool:
        """ì†ŒìŠ¤ ë° ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
        logger.info("ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ì¤‘...")
        
        try:
            # ì†ŒìŠ¤ DB ì—°ê²° í™•ì¸
            with self.source_engine.connect() as conn:
                result = conn.execute(text("SELECT 1"))
                if result.fetchone()[0] == 1:
                    logger.info("âœ… ì†ŒìŠ¤ DB (localhost) ì—°ê²° ì„±ê³µ")
                else:
                    logger.error("âŒ ì†ŒìŠ¤ DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                    return False
            
            # ëŒ€ìƒ DB ì—°ê²° í™•ì¸
            with self.target_engine.connect() as conn:
                result = conn.execute(text("SELECT 1"))
                if result.fetchone()[0] == 1:
                    logger.info("âœ… ëŒ€ìƒ DB (db.hellobdd2.gabia.io) ì—°ê²° ì„±ê³µ")
                else:
                    logger.error("âŒ ëŒ€ìƒ DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def get_table_count(self, engine: create_engine, table_name: str) -> int:
        """í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ"""
        try:
            with engine.connect() as conn:
                result = conn.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                return result.fetchone()[0]
        except Exception as e:
            logger.error(f"í…Œì´ë¸” {table_name} ì¹´ìš´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def migrate_communities(self) -> bool:
        """ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            # ì†ŒìŠ¤ì—ì„œ ì»¤ë®¤ë‹ˆí‹° ì¡°íšŒ
            with self.source_engine.connect() as conn:
                result = conn.execute(text("SELECT * FROM communities"))
                source_communities = result.fetchall()
            
            migrated_count = 0
            for community in source_communities:
                try:
                    # ëŒ€ìƒ DBì— ì»¤ë®¤ë‹ˆí‹° ì¶”ê°€ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
                    with self.target_engine.connect() as conn:
                        # ê¸°ì¡´ ì»¤ë®¤ë‹ˆí‹° í™•ì¸
                        check_result = conn.execute(
                            text("SELECT id FROM communities WHERE name = :name"),
                            {"name": community[1]}
                        )
                        existing = check_result.fetchone()
                        
                        if existing:
                            logger.debug(f"ì»¤ë®¤ë‹ˆí‹° ì´ë¯¸ ì¡´ì¬: {community[1]}")
                            continue
                        
                        # ìƒˆ ì»¤ë®¤ë‹ˆí‹° ì‚½ì…
                        conn.execute(
                            text("""
                                INSERT INTO communities (name, created_at, description)
                                VALUES (:name, :created_at, :description)
                            """),
                            {
                                "name": community[1],
                                "created_at": community[2] or datetime.now(),
                                "description": community[3] or ""
                            }
                        )
                        conn.commit()
                        migrated_count += 1
                        logger.debug(f"ì»¤ë®¤ë‹ˆí‹° ë§ˆì´ê·¸ë ˆì´ì…˜: {community[1]}")
                        
                except Exception as e:
                    logger.warning(f"ì»¤ë®¤ë‹ˆí‹° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {community[1]} - {e}")
            
            logger.info(f"âœ… ì»¤ë®¤ë‹ˆí‹° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}/{len(source_communities)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì»¤ë®¤ë‹ˆí‹° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def migrate_articles(self) -> bool:
        """ê²Œì‹œê¸€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ ê²Œì‹œê¸€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            # ì†ŒìŠ¤ì—ì„œ ê²Œì‹œê¸€ ì¡°íšŒ
            with self.source_engine.connect() as conn:
                result = conn.execute(text("SELECT * FROM articles"))
                source_articles = result.fetchall()
            
            migrated_count = 0
            for article in source_articles:
                try:
                    # ëŒ€ìƒ DBì— ê²Œì‹œê¸€ ì¶”ê°€ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
                    with self.target_engine.connect() as conn:
                        # ê¸°ì¡´ ê²Œì‹œê¸€ í™•ì¸
                        check_result = conn.execute(
                            text("""
                                SELECT id FROM articles 
                                WHERE platform_id = :platform_id 
                                AND community_article_id = :community_article_id
                            """),
                            {
                                "platform_id": article[1],
                                "community_article_id": article[2]
                            }
                        )
                        existing = check_result.fetchone()
                        
                        if existing:
                            logger.debug(f"ê²Œì‹œê¸€ ì´ë¯¸ ì¡´ì¬: {article[1]}/{article[2]}")
                            continue
                        
                        # ìƒˆ ê²Œì‹œê¸€ ì‚½ì…
                        conn.execute(
                            text("""
                                INSERT INTO articles (
                                    platform_id, community_article_id, community_id, title, content,
                                    images, writer_nickname, writer_id, like_count, comment_count,
                                    view_count, created_at, category_name, collected_at
                                ) VALUES (
                                    :platform_id, :community_article_id, :community_id, :title, :content,
                                    :images, :writer_nickname, :writer_id, :like_count, :comment_count,
                                    :view_count, :created_at, :category_name, :collected_at
                                )
                            """),
                            {
                                "platform_id": article[1],
                                "community_article_id": article[2],
                                "community_id": article[3],
                                "title": article[4],
                                "content": article[5],
                                "images": article[6],
                                "writer_nickname": article[7],
                                "writer_id": article[8],
                                "like_count": article[9] or 0,
                                "comment_count": article[10] or 0,
                                "view_count": article[11] or 0,
                                "created_at": article[12] or datetime.now(),
                                "category_name": article[13],
                                "collected_at": article[14] or datetime.now()
                            }
                        )
                        conn.commit()
                        migrated_count += 1
                        
                        if migrated_count % 100 == 0:
                            logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(source_articles)} ê²Œì‹œê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                        
                except Exception as e:
                    logger.warning(f"ê²Œì‹œê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {article[1]}/{article[2]} - {e}")
            
            logger.info(f"âœ… ê²Œì‹œê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}/{len(source_articles)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ê²Œì‹œê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def migrate_comments(self) -> bool:
        """ëŒ“ê¸€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ ëŒ“ê¸€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            # ì†ŒìŠ¤ì—ì„œ ëŒ“ê¸€ ì¡°íšŒ
            with self.source_engine.connect() as conn:
                result = conn.execute(text("SELECT * FROM comments"))
                source_comments = result.fetchall()
            
            migrated_count = 0
            for comment in source_comments:
                try:
                    # ëŒ€ìƒ DBì—ì„œ í•´ë‹¹ ê²Œì‹œê¸€ ì°¾ê¸°
                    with self.target_engine.connect() as conn:
                        article_result = conn.execute(
                            text("""
                                SELECT id FROM articles 
                                WHERE platform_id = :platform_id 
                                AND community_article_id = :community_article_id
                            """),
                            {
                                "platform_id": comment[1],
                                "community_article_id": comment[2]
                            }
                        )
                        target_article = article_result.fetchone()
                        
                        if not target_article:
                            logger.warning(f"ëŒ“ê¸€ì˜ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {comment[1]}/{comment[2]}")
                            continue
                        
                        # ê¸°ì¡´ ëŒ“ê¸€ í™•ì¸
                        check_result = conn.execute(
                            text("""
                                SELECT id FROM comments 
                                WHERE platform_id = :platform_id 
                                AND community_comment_id = :community_comment_id
                            """),
                            {
                                "platform_id": comment[1],
                                "community_comment_id": comment[3]
                            }
                        )
                        existing = check_result.fetchone()
                        
                        if existing:
                            logger.debug(f"ëŒ“ê¸€ ì´ë¯¸ ì¡´ì¬: {comment[3]}")
                            continue
                        
                        # ìƒˆ ëŒ“ê¸€ ì‚½ì…
                        conn.execute(
                            text("""
                                INSERT INTO comments (
                                    platform_id, community_article_id, community_comment_id, content,
                                    writer_nickname, writer_id, created_at, parent_comment_id,
                                    collected_at, article_id
                                ) VALUES (
                                    :platform_id, :community_article_id, :community_comment_id, :content,
                                    :writer_nickname, :writer_id, :created_at, :parent_comment_id,
                                    :collected_at, :article_id
                                )
                            """),
                            {
                                "platform_id": comment[1],
                                "community_article_id": comment[2],
                                "community_comment_id": comment[3],
                                "content": comment[4],
                                "writer_nickname": comment[5],
                                "writer_id": comment[6],
                                "created_at": comment[7] or datetime.now(),
                                "parent_comment_id": comment[8],
                                "collected_at": comment[9] or datetime.now(),
                                "article_id": target_article[0]
                            }
                        )
                        conn.commit()
                        migrated_count += 1
                        
                        if migrated_count % 100 == 0:
                            logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(source_comments)} ëŒ“ê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                        
                except Exception as e:
                    logger.warning(f"ëŒ“ê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {comment[3]} - {e}")
            
            logger.info(f"âœ… ëŒ“ê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}/{len(source_comments)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëŒ“ê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def migrate_reviews(self) -> bool:
        """í›„ê¸° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ í›„ê¸° ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            # ì†ŒìŠ¤ì—ì„œ í›„ê¸° ì¡°íšŒ
            with self.source_engine.connect() as conn:
                result = conn.execute(text("SELECT * FROM reviews"))
                source_reviews = result.fetchall()
            
            migrated_count = 0
            for review in source_reviews:
                try:
                    # ëŒ€ìƒ DBì— í›„ê¸° ì¶”ê°€ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
                    with self.target_engine.connect() as conn:
                        # ê¸°ì¡´ í›„ê¸° í™•ì¸
                        check_result = conn.execute(
                            text("""
                                SELECT id FROM reviews 
                                WHERE platform_id = :platform_id 
                                AND platform_review_id = :platform_review_id
                            """),
                            {
                                "platform_id": review[1],
                                "platform_review_id": review[2]
                            }
                        )
                        existing = check_result.fetchone()
                        
                        if existing:
                            logger.debug(f"í›„ê¸° ì´ë¯¸ ì¡´ì¬: {review[1]}/{review[2]}")
                            continue
                        
                        # ìƒˆ í›„ê¸° ì‚½ì…
                        conn.execute(
                            text("""
                                INSERT INTO reviews (
                                    platform_id, platform_review_id, community_id, title, content,
                                    images, writer_nickname, writer_id, like_count, rating, price,
                                    categories, sub_categories, surgery_date, hospital_name, doctor_name,
                                    is_blind, is_image_blur, is_certificated_review, created_at, collected_at
                                ) VALUES (
                                    :platform_id, :platform_review_id, :community_id, :title, :content,
                                    :images, :writer_nickname, :writer_id, :like_count, :rating, :price,
                                    :categories, :sub_categories, :surgery_date, :hospital_name, :doctor_name,
                                    :is_blind, :is_image_blur, :is_certificated_review, :created_at, :collected_at
                                )
                            """),
                            {
                                "platform_id": review[1],
                                "platform_review_id": review[2],
                                "community_id": review[3],
                                "title": review[4],
                                "content": review[5],
                                "images": review[6],
                                "writer_nickname": review[7],
                                "writer_id": review[8],
                                "like_count": review[9] or 0,
                                "rating": review[10] or 0,
                                "price": review[11] or 0,
                                "categories": review[12],
                                "sub_categories": review[13],
                                "surgery_date": review[14],
                                "hospital_name": review[15],
                                "doctor_name": review[16],
                                "is_blind": bool(review[17]) if review[17] is not None else False,
                                "is_image_blur": bool(review[18]) if review[18] is not None else False,
                                "is_certificated_review": bool(review[19]) if review[19] is not None else False,
                                "created_at": review[20] or datetime.now(),
                                "collected_at": review[21] or datetime.now()
                            }
                        )
                        conn.commit()
                        migrated_count += 1
                        
                        if migrated_count % 100 == 0:
                            logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(source_reviews)} í›„ê¸° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                        
                except Exception as e:
                    logger.warning(f"í›„ê¸° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {review[1]}/{review[2]} - {e}")
            
            logger.info(f"âœ… í›„ê¸° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}/{len(source_reviews)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í›„ê¸° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_migration_statistics(self) -> Dict:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„ ì¡°íšŒ"""
        logger.info("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„ ì¡°íšŒ ì¤‘...")
        
        try:
            # ì†ŒìŠ¤ DB í†µê³„
            source_stats = {
                'communities': self.get_table_count(self.source_engine, 'communities'),
                'articles': self.get_table_count(self.source_engine, 'articles'),
                'comments': self.get_table_count(self.source_engine, 'comments'),
                'reviews': self.get_table_count(self.source_engine, 'reviews')
            }
            
            # ëŒ€ìƒ DB í†µê³„
            target_stats = {
                'communities': self.get_table_count(self.target_engine, 'communities'),
                'articles': self.get_table_count(self.target_engine, 'articles'),
                'comments': self.get_table_count(self.target_engine, 'comments'),
                'reviews': self.get_table_count(self.target_engine, 'reviews')
            }
            
            return {
                'source': source_stats,
                'target': target_stats
            }
            
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def run_migration(self) -> bool:
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ğŸš€ localhost â†’ db.hellobdd2.gabia.io ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        logger.info("=" * 80)
        
        # ì—°ê²° í™•ì¸
        if not self.check_connections():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ í†µê³„
        logger.info("\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ í†µê³„:")
        pre_stats = self.get_migration_statistics()
        if pre_stats:
            logger.info(f"ì†ŒìŠ¤ DB (localhost): {pre_stats['source']}")
            logger.info(f"ëŒ€ìƒ DB (gabia.io): {pre_stats['target']}")
        
        # ìˆœì„œëŒ€ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        migration_steps = [
            ("ì»¤ë®¤ë‹ˆí‹°", self.migrate_communities),
            ("ê²Œì‹œê¸€", self.migrate_articles),
            ("ëŒ“ê¸€", self.migrate_comments),
            ("í›„ê¸°", self.migrate_reviews)
        ]
        
        for step_name, step_function in migration_steps:
            logger.info(f"\nğŸ“‹ {step_name} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
            if not step_function():
                logger.error(f"âŒ {step_name} ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ í†µê³„
        logger.info("\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ í†µê³„:")
        post_stats = self.get_migration_statistics()
        if post_stats:
            logger.info(f"ì†ŒìŠ¤ DB (localhost): {post_stats['source']}")
            logger.info(f"ëŒ€ìƒ DB (gabia.io): {post_stats['target']}")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ ëª¨ë“  ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ’¡ ì´ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëŒ€ìƒ DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("localhost â†’ db.hellobdd2.gabia.io ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬")
    logger.info("=" * 80)
    
    # ì‚¬ìš©ì í™•ì¸
    response = input("\nâš ï¸  ëŒ€ìƒ DBì˜ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€ë©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if response.lower() != 'y':
        logger.info("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrator = DatabaseMigrator()
    success = migrator.run_migration()
    
    if success:
        logger.info("\nğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info("1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •ì„ ëŒ€ìƒ DBë¡œ ë³€ê²½")
        logger.info("2. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘")
        logger.info("3. ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ë˜ì—ˆëŠ”ì§€ í™•ì¸")
    else:
        logger.error("\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()